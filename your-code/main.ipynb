{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define `docs` array that contains the paths of `doc1.txt`, `doc2.txt`, and `doc3.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['doc1.txt', 'doc2.txt', 'doc3.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an empty array `corpus` that will contain the content strings of the docs. Loop `docs` and read the content of each doc into the `corpus` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "# Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "docs = ['doc1.txt', 'doc2.txt', 'doc3.txt']\n",
    "corpus = []\n",
    "\n",
    "for doc in docs:\n",
    "    with open(doc) as f:\n",
    "        content = f.read()\n",
    "        corpus.append(content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ironhack is cool.', 'I love Ironhack.', 'I am a student at Ironhack.']\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print `corpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "docs = ['doc1.txt', 'doc2.txt', 'doc3.txt']\n",
    "corpus = []\n",
    "for doc in docs:\n",
    "    with open(doc, 'r') as f:\n",
    "        content = f.read()\n",
    "        content = re.sub(r'[^\\w\\s]', '', content).lower()\n",
    "        corpus.append(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ironhack is cool', 'i love ironhack', 'i am a student at ironhack']\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have seen:\n",
    "\n",
    "```['ironhack is cool', 'i love ironhack', 'i am a student at ironhack']```\n",
    "\n",
    "However, if your output is:\n",
    "\n",
    "```['Ironhack is cool.', 'I love Ironhack.', 'I am a student at Ironhack.']```\n",
    "\n",
    "This means you didn't:\n",
    "\n",
    "1. Remove punctuation from the strings;\n",
    "\n",
    "1. Convert strings to lowercase.\n",
    "\n",
    "Revise your code above until you receive the correct output for `corpus`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define `bag_of_words` as an empty array. It will contain the unique terms in `corpus`.\n",
    "\n",
    "Loop through `corpus`. In each loop, do the following:\n",
    "\n",
    "1. Break the string into an array of terms. \n",
    "1. Create a sub-loop to iterate the terms array. \n",
    "  * In each sub-loop, you'll check if the current term is already contained in `bag_of_words`. If not in `bag_of_words`, append it to the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ironhack', 'is', 'cool', 'i', 'love', 'am', 'a', 'student', 'at']\n"
     ]
    }
   ],
   "source": [
    "bag_of_words=[]\n",
    "for docs in corpus:\n",
    "    terms = docs.split()\n",
    "    for term in terms:\n",
    "        if term not in bag_of_words:\n",
    "            bag_of_words.append(term)\n",
    "            \n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print `bag_of_words`. You should see: \n",
    "\n",
    "```['ironhack', 'is', 'cool', 'i', 'love', 'am', 'a', 'student', 'at']```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define an empty array called `term_freq`. Loop `corpus` for a second time. In each loop, create a sub-loop to iterate the terms in `bag_of_words`. Count how many times each term appears in each doc of `corpus`. Append the term-frequency array to `term_freq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_freq = []\n",
    "\n",
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print `term_freq`. You should see:\n",
    "\n",
    "```[[1, 1, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 1, 1, 0, 0, 0, 0], [1, 0, 0, 1, 0, 1, 1, 1, 1]]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1, 0, 0, 0, 1, 0]\n",
      "[0, 1, 0, 1, 0, 0, 1, 0, 0]\n",
      "[1, 1, 0, 1, 1, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# docs = ['doc1.txt', 'doc2.txt', 'doc3.txt']\n",
    "# corpus = []\n",
    "# for doc in docs:\n",
    "#     with open(doc, 'r') as f:\n",
    "#         content = f.read()\n",
    "#         content = re.sub(r'[^\\w\\s]', '', content).lower()\n",
    "#         corpus.append(content)\n",
    "\n",
    "bag_of_words = set()\n",
    "for doc in corpus:\n",
    "    words = doc.split()\n",
    "    for word in words:\n",
    "        bag_of_words.add(word)\n",
    "\n",
    "term_freq = []\n",
    "\n",
    "for doc in corpus:\n",
    "    doc_words = doc.split()\n",
    "    tf_dict = {}\n",
    "    for word in bag_of_words:\n",
    "        tf_dict[word] = doc_words.count(word)\n",
    "    term_freq.append(tf_dict)\n",
    "    \n",
    "for doc in term_freq:\n",
    "    print(list(doc.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If your answer is correct, congratulations! You've solved the challenge!**\n",
    "\n",
    "If not, go back and check for errors in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 1, 1, 0, 0, 0, 1, 0], [0, 1, 0, 1, 0, 0, 1, 0, 0], [1, 1, 0, 1, 1, 1, 0, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# docs = ['doc1.txt', 'doc2.txt', 'doc3.txt']\n",
    "# corpus = []\n",
    "# for doc in docs:\n",
    "#     with open(doc, 'r') as f:\n",
    "#         content = f.read()\n",
    "#         content = re.sub(r'[^\\w\\s]', '', content).lower()\n",
    "#         corpus.append(content)\n",
    "\n",
    "bag_of_words = set()\n",
    "for doc in corpus:\n",
    "    words = doc.split()\n",
    "    for word in words:\n",
    "        bag_of_words.add(word)\n",
    "\n",
    "term_freq = []\n",
    "\n",
    "for doc in corpus:\n",
    "    doc_words = doc.split()\n",
    "    tf_dict = {}\n",
    "    for word in bag_of_words:\n",
    "        tf_dict[word] = doc_words.count(word)\n",
    "    term_freq.append(tf_dict)\n",
    "# Crea una lista anidada con los valores de los tres diccionarios\n",
    "tf_list = []\n",
    "for doc in term_freq:\n",
    "    doc_tf = []\n",
    "    for value in doc.values():\n",
    "        doc_tf.append(value)\n",
    "    tf_list.append(doc_tf)\n",
    "\n",
    "print(tf_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
